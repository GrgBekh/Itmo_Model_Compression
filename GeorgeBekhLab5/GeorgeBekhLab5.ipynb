{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a2bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnx) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnx) (4.24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnx) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import numpy as np\n",
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c6c4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168c527a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrou\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0\n",
      "                   all          4         17       0.87       0.92      0.947      0.719\n",
      "                person          4         10      0.855       0.59      0.707      0.379\n",
      "                   dog          4          1      0.886          1      0.995      0.796\n",
      "                 horse          4          2      0.794          1      0.995        0.8\n",
      "              elephant          4          2          1      0.931      0.995       0.55\n",
      "              umbrella          4          1      0.686          1      0.995      0.895\n",
      "          potted plant          4          1          1          1      0.995      0.895\n",
      "Speed: 1.0ms preprocess, 238.7ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0, 16, 17, 20, 25, 58])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000027D06A5BB10>\n",
       "fitness: 0.7420759443667307\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.37864,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,       0.796,      0.8001,     0.71931,     0.71931,     0.55014,     0.71931,     0.71931,     0.71931,\n",
       "           0.71931,      0.8955,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,\n",
       "           0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,      0.8955,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,\n",
       "           0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931,     0.71931])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8701713420825671, 'metrics/recall(B)': 0.9202653909068802, 'metrics/mAP50(B)': 0.9469403013347323, 'metrics/mAP50-95(B)': 0.7193132380369528, 'fitness': 0.7420759443667307}\n",
       "save_dir: WindowsPath('runs/detect/val3')\n",
       "speed: {'preprocess': 1.0383129119873047, 'inference': 238.72435092926025, 'loss': 0.0, 'postprocess': 3.963291645050049}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(data = 'coco8.yaml', device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1de87d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (21.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxsim>=0.4.33', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "Collecting onnxsim>=0.4.33\n",
      "  Obtaining dependency information for onnxsim>=0.4.33 from https://files.pythonhosted.org/packages/55/c7/f2ff2f96e589b2b4550598d2dc75f619da7d45441f6ad4e627141deba7d7/onnxsim-0.4.35-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnxsim-0.4.35-cp311-cp311-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting onnxruntime-gpu\n",
      "  Obtaining dependency information for onnxruntime-gpu from https://files.pythonhosted.org/packages/a6/62/4f5f015cf6fbe7345f40ab73b58decde6970ae773fc616bb493662ff9b87/onnxruntime_gpu-1.16.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnxruntime_gpu-1.16.1-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: onnx in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxsim>=0.4.33) (1.14.1)\n",
      "Collecting rich (from onnxsim>=0.4.33)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting coloredlogs (from onnxruntime-gpu)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxruntime-gpu) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxruntime-gpu) (23.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxruntime-gpu) (4.24.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from onnx->onnxsim>=0.4.33) (4.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from rich->onnxsim>=0.4.33) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from rich->onnxsim>=0.4.33) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->onnxsim>=0.4.33) (0.1.0)\n",
      "Downloading onnxsim-0.4.35-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 1.2/1.2 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading onnxruntime_gpu-1.16.1-cp311-cp311-win_amd64.whl (125.7 MB)\n",
      "   --------------------------------------- 125.7/125.7 MB 34.4 MB/s eta 0:00:00\n",
      "Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 239.8/239.8 kB ? eta 0:00:00\n",
      "Installing collected packages: pyreadline3, humanfriendly, rich, coloredlogs, onnxsim, onnxruntime-gpu\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.16.1 onnxsim-0.4.35 pyreadline3-3.4.1 rich-13.6.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  16.4s, installed 2 packages: ['onnxsim>=0.4.33', 'onnxruntime-gpu']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  20.5s, saved as 'yolov8s.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (22.4s)\n",
      "Results saved to \u001b[1mC:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\GeorgeBekhLab1\\GeorgeBekhLab5\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8s.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8s.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s.onnx'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format = 'onnx', simplify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26460798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.1 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.35...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.6s, saved as 'yolov8s.onnx' (42.7 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino-dev>=2023.0'] not found, attempting AutoUpdate...\n",
      "Collecting openvino-dev>=2023.0\n",
      "  Obtaining dependency information for openvino-dev>=2023.0 from https://files.pythonhosted.org/packages/86/65/76ce426ac1e1d7db560187440b307be10af108a92d28e3e1842e388989db/openvino_dev-2023.1.0-12185-py3-none-any.whl.metadata\n",
      "  Downloading openvino_dev-2023.1.0-12185-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting addict>=2.4.0 (from openvino-dev>=2023.0)\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (0.7.1)\n",
      "Collecting jstyleson>=0.0.2 (from openvino-dev>=2023.0)\n",
      "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: networkx<=3.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (3.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (1.24.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (4.8.1.78)\n",
      "Collecting openvino-telemetry>=2022.1.0 (from openvino-dev>=2023.0)\n",
      "  Obtaining dependency information for openvino-telemetry>=2022.1.0 from https://files.pythonhosted.org/packages/b7/9c/9262c50dfb6ac8dd9d71ddd9f1c90e896d3ffc6c58bef4837d82cb20ed56/openvino_telemetry-2023.2.1-py3-none-any.whl.metadata\n",
      "  Downloading openvino_telemetry-2023.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pillow>=8.1.2 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (6.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (2.31.0)\n",
      "Collecting texttable>=1.6.3 (from openvino-dev>=2023.0)\n",
      "  Obtaining dependency information for texttable>=1.6.3 from https://files.pythonhosted.org/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (4.65.0)\n",
      "Collecting openvino==2023.1.0 (from openvino-dev>=2023.0)\n",
      "  Obtaining dependency information for openvino==2023.1.0 from https://files.pythonhosted.org/packages/e5/b1/6cc8b15910d90252663ebdfced1d6b9b7f0f0ef494cbe532e70044ea04e1/openvino-2023.1.0-12185-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading openvino-2023.1.0-12185-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: scipy<1.11,>=1.8 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from openvino-dev>=2023.0) (1.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from requests>=2.25.1->openvino-dev>=2023.0) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\gbekh\\anaconda3\\lib\\site-packages (from tqdm>=4.54.1->openvino-dev>=2023.0) (0.4.6)\n",
      "Downloading openvino_dev-2023.1.0-12185-py3-none-any.whl (5.8 MB)\n",
      "   ---------------------------------------- 5.8/5.8 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading openvino-2023.1.0-12185-cp311-cp311-win_amd64.whl (28.7 MB)\n",
      "   ---------------------------------------- 28.7/28.7 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading openvino_telemetry-2023.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: jstyleson\n",
      "  Building wheel for jstyleson (setup.py): started\n",
      "  Building wheel for jstyleson (setup.py): finished with status 'done'\n",
      "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2392 sha256=fd46e92a9b56c8b828b6936cc7ea71887f0f4c7db881760a03f28df7b7c1a0d9\n",
      "  Stored in directory: C:\\Users\\gbekh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-21gn9d5f\\wheels\\ad\\63\\0e\\50090147fb424100f7d9078b71c21b9e7468b6f643515a60d6\n",
      "Successfully built jstyleson\n",
      "Installing collected packages: texttable, openvino-telemetry, jstyleson, addict, openvino, openvino-dev\n",
      "Successfully installed addict-2.4.0 jstyleson-0.0.2 openvino-2023.1.0 openvino-dev-2023.1.0 openvino-telemetry-2023.2.1 texttable-1.7.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  45.4s, installed 1 package: ['openvino-dev>=2023.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2023.1.0-12185-9e6b00e51cd-releases/2023/1...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  51.0s, saved as 'yolov8s_openvino_model\\' (42.9 MB)\n",
      "\n",
      "Export complete (54.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\GeorgeBekhLab1\\GeorgeBekhLab5\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8s_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8s_openvino_model imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8s_openvino_model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format = 'openvino', simplify = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00ca4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc96cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "YOLOv8s summary (fused): 168 layers, 11156544 parameters, 0 gradients\n",
      "\n",
      "image 1/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000009.jpg: 480x640 3 bowls, 1 orange, 2 broccolis, 489.1ms\n",
      "image 2/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000025.jpg: 448x640 2 giraffes, 488.8ms\n",
      "image 3/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000030.jpg: 448x640 1 potted plant, 1 vase, 446.7ms\n",
      "image 4/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000034.jpg: 448x640 1 zebra, 393.7ms\n",
      "Speed: 2.1ms preprocess, 454.6ms inference, 6.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo predict source = C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train task=detect \\\n",
    "    model=yolov8s.pt imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e992d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "Loading yolov8s.onnx for ONNX Runtime inference...\n",
      "\n",
      "image 1/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000009.jpg: 640x640 3 bowls, 2 oranges, 2 broccolis, 282.0ms\n",
      "image 2/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000025.jpg: 640x640 2 giraffes, 282.0ms\n",
      "image 3/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000030.jpg: 640x640 1 potted plant, 1 vase, 289.0ms\n",
      "image 4/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000034.jpg: 640x640 1 zebra, 300.0ms\n",
      "Speed: 8.0ms preprocess, 288.2ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo predict source = C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train task=detect \\\n",
    "    model=yolov8s.onnx imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa17e872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.181  Python-3.11.4 torch-2.2.0.dev20230918+cu121 CPU (12th Gen Intel Core(TM) i7-12650H)\n",
      "Loading yolov8s_openvino_model for OpenVINO inference...\n",
      "\n",
      "image 1/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000009.jpg: 640x640 3 bowls, 2 oranges, 2 broccolis, 1198.7ms\n",
      "image 2/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000025.jpg: 640x640 2 giraffes, 866.3ms\n",
      "image 3/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000030.jpg: 640x640 1 potted plant, 1 vase, 1049.4ms\n",
      "image 4/4 C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train\\000000000034.jpg: 640x640 1 zebra, 1029.1ms\n",
      "Speed: 7.8ms preprocess, 1035.9ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict6\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo predict source = C:\\Users\\gbekh\\JupiterProjects\\ProjectCompression\\datasets\\coco8\\images\\train task=detect \\\n",
    "    model=yolov8s_openvino_model imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd1ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34521d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a09c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d718ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951409b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531c7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
